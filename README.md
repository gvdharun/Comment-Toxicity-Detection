# üö® Deep Learning for Comment Toxicity Detection with Streamlit üö®

Welcome to the **Comment Toxicity Detection** project ‚Äî a deep learning-powered system to automatically identify toxic comments in online discussions, fostering safer and healthier communities.

---

## üöÄ Project Overview

Online platforms struggle with toxic comments such as harassment, hate speech, and offensive language. This project develops a **deep learning model** to detect and flag such comments in real-time.

- Built with **Python**, **TensorFlow**, **NLP**, and **Streamlit**
- Supports multiple toxicity categories:  
  - Toxic  
  - Severe Toxic  
  - Obscene  
  - Threat  
  - Insult  
  - Identity Hate  

---

## üõ†Ô∏è Features

- üîç Real-time toxicity prediction in an interactive web app  
- üìÅ Bulk comment toxicity analysis via CSV upload  
- üìä Visual display of data insights & model performance  
- ü§ñ Deep learning models using CNN, LSTM, and BERT architectures  
- ‚öôÔ∏è Easy deployment with detailed setup guide

---

## üìÇ Project Structure

```
‚îú‚îÄ‚îÄ models/ # Saved trained models
‚îú‚îÄ‚îÄ data/ # Dataset files and samples
‚îú‚îÄ‚îÄ toxic_app.py # Streamlit application script
‚îú‚îÄ‚îÄ comment_toxicity.ipynb # jupyter notebook (Preprocessing, Model training)
‚îú‚îÄ‚îÄ requirements.txt # Python dependencies
‚îî‚îÄ‚îÄ README.md # Project documentation
```


---

## üìà Model Performance Summary

| Model      | Training Accuracy | Validation Accuracy | Remarks                               |
|------------|-------------------|---------------------|-------------------------------------|
| CNN        | ~99.4%            | ~99.40%              | Fast, good baseline                  |
| LSTM       | ~99.39%           | ~99.40%               | Better context modeling              |
| BERT       | >95% (typical)    | >95% (typical)      | State-of-the-art contextual model   |

---

## Best Model: Convolutional Neural Network (CNN)

- **Architecture Highlights:**
  - Embedding layer to convert tokens into dense vectors.
  - 1D Convolutional layer to capture local phrase patterns.
  - Global max pooling for robust feature extraction.
  - Fully connected dense layers for multi-label binary classification.

- **Performance:**
  - **Training Accuracy:** ~99.4%
  - **Validation Accuracy:** ~99.4%
  - **Training Loss:** ~0.13
  - **Validation Loss:** ~0.14

> The CNN model strikes a good balance between accuracy, training speed, and resource efficiency, making it an excellent choice for deployment in practical toxicity detection systems.

---

## üñ•Ô∏è Getting Started

1. Clone this repository  
`git clone https://github.com/gvdharun/Comment-Toxicity-Detection.git`


2. Install dependencies  
`pip install -r requirements.txt`


3. Run the Streamlit app  
`streamlit run toxic_app.py`

---

## Usage üéØ

- Input single comments via the Streamlit text box for toxicity prediction.
- Upload CSV files with a `comment_text` column for batch predictions.
- View model metrics and sample test data insights on the dashboard.
- Download prediction results as CSV.

---

## Project Deliverables üì¶

- Deep learning model files for toxicity detection
- Complete Streamlit application source code
- Deployment guide with instructions
- Supplementary documentation and video demonstration

---

## Conclusion üéâ

This project delivers a **robust and scalable solution** for automating the detection of toxicity in user-generated comments. By leveraging advanced deep learning architectures and an intuitive Streamlit interface, it empowers social media platforms, forums, educational sites, and media outlets to **maintain healthier online environments** through efficient content moderation.

The modular design facilitates easy extension, enabling future integration of state-of-the-art transformer models and continuous improvements in accuracy and usability.

---
