# ğŸš¨ Deep Learning for Comment Toxicity Detection with Streamlit ğŸš¨

Welcome to the **Comment Toxicity Detection** project â€” a deep learning-powered system to automatically identify toxic comments in online discussions, fostering safer and healthier communities.

---

## ğŸš€ Project Overview

Online platforms struggle with toxic comments such as harassment, hate speech, and offensive language. This project develops a **deep learning model** to detect and flag such comments in real-time.

- Built with **Python**, **TensorFlow**, **NLP**, and **Streamlit**
- Supports multiple toxicity categories:  
  - Toxic  
  - Severe Toxic  
  - Obscene  
  - Threat  
  - Insult  
  - Identity Hate  

---

## ğŸ› ï¸ Features

- ğŸ” Real-time toxicity prediction in an interactive web app  
- ğŸ“ Bulk comment toxicity analysis via CSV upload  
- ğŸ“Š Visual display of data insights & model performance  
- ğŸ¤– Deep learning models using CNN, LSTM, and BERT architectures  
- âš™ï¸ Easy deployment with detailed setup guide

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ models/ # Saved trained models
â”œâ”€â”€ data/ # Dataset files and samples
â”œâ”€â”€ toxic_app.py # Streamlit application script
â”œâ”€â”€ comment_toxicity.ipynb # jupyter notebook (Preprocessing, Model training)
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation
```


---

## ğŸ“ˆ Model Performance Summary

| Model      | Training Accuracy | Validation Accuracy | Remarks                               |
|------------|-------------------|---------------------|-------------------------------------|
| CNN        | ~99.4%            | ~99.4%              | Fast, good baseline                  |
| LSTM       | (TBD)             | (TBD)               | Better context modeling              |
| BERT       | >95% (typical)    | >95% (typical)      | State-of-the-art contextual model   |

---

## ğŸ–¥ï¸ Getting Started

1. Clone this repository  
`git clone https://github.com/yourusername/comment-toxicity-detection.git`


2. Install dependencies  
`pip install -r requirements.txt`


3. Run the Streamlit app  
`streamlit run toxic_app.py`

---

## Usage ğŸ¯

- Input single comments via the Streamlit text box for toxicity prediction.
- Upload CSV files with a `comment_text` column for batch predictions.
- View model metrics and sample test data insights on the dashboard.
- Download prediction results as CSV.

---

## Project Deliverables ğŸ“¦

- Deep learning model files for toxicity detection
- Complete Streamlit application source code
- Deployment guide with instructions
- Supplementary documentation and video demonstration

---

## Conclusion ğŸ‰

This project delivers a **robust and scalable solution** for automating the detection of toxicity in user-generated comments. By leveraging advanced deep learning architectures and an intuitive Streamlit interface, it empowers social media platforms, forums, educational sites, and media outlets to **maintain healthier online environments** through efficient content moderation.

The modular design facilitates easy extension, enabling future integration of state-of-the-art transformer models and continuous improvements in accuracy and usability.

---
